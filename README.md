# Cross-imgGraph
## Weakly Supervised Disease Localization in Chest X-rays via Looking into Image Relations
### abstract
Locating diseases in chest X-ray images with few careful annotations saves large human effort in annotation. Recent works tackled this problem with innovative weakly-supervised algorithms, however, the performance of these methods on X-ray analysis is not as good as in the general computer vision tasks. Different from natural images, the global structure of different chest X-rays are relatively consistent and the disease regions are relatively inconspicuous, and radiologists often need to compare multiple images to make diagnostic decisions. Inspired by this, we propose a hypothesis that the explicit modelling of the image-to-image relationship is beneficial to the learning machines, especially when the supervision is insufficient. To model the relationship, we exploit a cross-image graph method to excavate the structural relationship between X-ray images. Different from the attention-based methods, the proposed method represents the inter-image relationship as in-batch graphs, where each X-ray image is regarded as a node and the distance between X-ray images is defined as an edge. The graphs are used as regularizers to help preserve the structural similarity between image pairs in the embedding space. By means of this, our approach achieves the state-of-the-art result on NIH chest X-ray dataset for disease localization with limited supervision. As open science, we make our codes accessible online.
